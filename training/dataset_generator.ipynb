{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python"
      ],
      "metadata": {
        "id": "4G91XOYrFnsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdvjwTZ4FgDO"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "id": "U08I340jFveS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the process_image function as provided before\n",
        "\n",
        "def get_grayscale(image):\n",
        "    # Convert image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Gaussian Blur\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (9, 9), 0)\n",
        "    # Enhance contrast\n",
        "    contrast_enhanced = cv2.equalizeHist(blurred_image)\n",
        "\n",
        "    # Resize image to maintain 1:1 aspect ratio and make it 128x128\n",
        "    target_size = 128\n",
        "    height, width = contrast_enhanced.shape\n",
        "    scale = target_size / max(height, width)\n",
        "    resized_image = cv2.resize(contrast_enhanced, (int(width * scale), int(height * scale)), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Centering the image in a 128x128 frame\n",
        "    delta_w = target_size - resized_image.shape[1]\n",
        "    delta_h = target_size - resized_image.shape[0]\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    # Add border to make the image exactly 128x128\n",
        "    final_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "    # Display the final processed image\n",
        "    # plt.figure(figsize=(3, 3))\n",
        "    # plt.imshow(final_image, cmap='gray')\n",
        "    # plt.title(\"Processed Image\")\n",
        "    # plt.axis('off')\n",
        "    # plt.show()\n",
        "\n",
        "    return final_image\n",
        "\n",
        "def process_image(image):\n",
        "    mp_hands = mp.solutions.hands\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
        "        results = hands.process(image)\n",
        "        if results.multi_hand_landmarks:\n",
        "            hand_landmarks = results.multi_hand_landmarks[0]\n",
        "            h, w, _ = image.shape\n",
        "\n",
        "            # Create a mask for drawing landmarks\n",
        "            mask = np.zeros((h, w), dtype=np.uint8)\n",
        "            mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            # Draw landmarks and connections using MediaPipe drawing utils\n",
        "            mp_drawing.draw_landmarks(\n",
        "                mask_bgr, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
        "                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=4, circle_radius=2),\n",
        "                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=22)\n",
        "            )\n",
        "\n",
        "            mask = cv2.cvtColor(mask_bgr, cv2.COLOR_BGR2GRAY)\n",
        "            kernel = np.ones((15, 15), np.uint8)\n",
        "\n",
        "\n",
        "            # Determine palm points for fillPoly\n",
        "            palm_indices = [0, 2, 5, 9, 13, 17]  # Indices for wrist and bases of each finger\n",
        "            palm_points = np.array([[\n",
        "                int(hand_landmarks.landmark[idx].x * w),\n",
        "                int(hand_landmarks.landmark[idx].y * h)\n",
        "            ] for idx in palm_indices], dtype=np.int32)\n",
        "\n",
        "            # Fill the palm area on the mask\n",
        "            cv2.fillPoly(mask, [palm_points], (255, 255, 255))\n",
        "            mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "            # Find contours to determine the bounding box of the hand\n",
        "            contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            if contours:\n",
        "                cnt = max(contours, key=cv2.contourArea)  # find the largest contour\n",
        "                x, y, w, h = cv2.boundingRect(cnt)\n",
        "\n",
        "                # Crop and resize the mask\n",
        "                cropped_mask = mask[y:y+h, x:x+w]\n",
        "                final_img = cv2.resize(cropped_mask, (128, 128))\n",
        "\n",
        "                plt.figure(figsize=(3, 3))\n",
        "                plt.imshow(final_img, cmap='gray')\n",
        "                plt.title(\"Processed Image\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "\n",
        "                return [final_img, None]\n",
        "        else:\n",
        "            return [None, None]"
      ],
      "metadata": {
        "id": "NGtGWRoWFleJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full_dir_path = os.path.join(base_dir, dir_name)\n",
        "training_path = '/content/drive/MyDrive/training_vids'\n",
        "output_path = '/content/drive/MyDrive/training_v2'\n",
        "# Create directories if they do not exist\n",
        "if not os.path.exists('frame_hands_v2'):\n",
        "    os.makedirs('frame_hands_v2')\n",
        "if not os.path.exists('bw_plain_hands_v3'):\n",
        "    os.makedirs('bw_plain_hands_v3')\n",
        "\n",
        "# Load the video\n",
        "videos = [\"closed_left\", \"closed_right\", \"open_left\", \"open_right\"]\n",
        "for vid in videos:\n",
        "  file_name = f'{training_path}/{vid}.mp4'\n",
        "  cap = cv2.VideoCapture(file_name)\n",
        "  frame_number = 0\n",
        "\n",
        "  while cap.isOpened():\n",
        "      print(\"Frame number:\", frame_number)\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "          break\n",
        "\n",
        "      # Process the image\n",
        "      processed_image, bw_image = process_image(frame)\n",
        "      source_video = file_name.split(\"/\")[-1][:-4]\n",
        "      if processed_image is not None:\n",
        "          cv2.imwrite(f'{output_path}/frame_hands_v2/frame_{source_video}_{frame_number}.png', processed_image)\n",
        "          # cv2.imwrite(f'{output_path}/bw_plain_hands_v3/frame_{source_video}_{frame_number}.png', bw_image)\n",
        "          print(f'SAVED: {output_path}/frame_hands_v2/frame_{source_video}_{frame_number}.png')\n",
        "          # print(f'SAVED: {output_path}/bw_plain_hands_v3/frame_{source_video}_{frame_number}.png')\n",
        "\n",
        "      frame_number += 1\n",
        "\n",
        "cap.release()\n",
        "print(\"Processing complete.\")"
      ],
      "metadata": {
        "id": "EL-J70BWFm5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the process_image function as provided before\n",
        "\n",
        "def get_grayscale(image):\n",
        "    # Convert image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Gaussian Blur\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (9, 9), 0)\n",
        "    # Enhance contrast\n",
        "    contrast_enhanced = cv2.equalizeHist(blurred_image)\n",
        "\n",
        "    # Resize image to maintain 1:1 aspect ratio and make it 128x128\n",
        "    target_size = 128\n",
        "    height, width = contrast_enhanced.shape\n",
        "    scale = target_size / max(height, width)\n",
        "    resized_image = cv2.resize(contrast_enhanced, (int(width * scale), int(height * scale)), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Centering the image in a 128x128 frame\n",
        "    delta_w = target_size - resized_image.shape[1]\n",
        "    delta_h = target_size - resized_image.shape[0]\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    # Add border to make the image exactly 128x128\n",
        "    final_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "    # Display the final processed image\n",
        "    # plt.figure(figsize=(3, 3))\n",
        "    # plt.imshow(final_image, cmap='gray')\n",
        "    # plt.title(\"Processed Image\")\n",
        "    # plt.axis('off')\n",
        "    # plt.show()\n",
        "\n",
        "    return final_image\n",
        "\n",
        "def process_image(image):\n",
        "    mp_hands = mp.solutions.hands\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
        "        results = hands.process(image)\n",
        "        if results.multi_hand_landmarks:\n",
        "\n",
        "\n",
        "            hand_landmarks = results.multi_hand_landmarks[0]\n",
        "            h, w, _ = image.shape\n",
        "            x_min, x_max = int(min(lm.x for lm in hand_landmarks.landmark) * w), int(max(lm.x for lm in hand_landmarks.landmark) * w)\n",
        "            y_min, y_max = int(min(lm.y for lm in hand_landmarks.landmark) * h), int(max(lm.y for lm in hand_landmarks.landmark) * h)\n",
        "\n",
        "\n",
        "\n",
        "#----------------\n",
        "           # Adjust to keep the aspect ratio 1:1 and include padding\n",
        "            box_width = x_max - x_min\n",
        "            box_height = y_max - y_min\n",
        "            side_length = max(box_width, box_height)\n",
        "            padding = int(side_length * 0.05)\n",
        "            side_length += 2 * padding\n",
        "\n",
        "            # Center the square around the hand, adjust if it goes out of bounds\n",
        "            x_center = (x_min + x_max) // 2\n",
        "            y_center = (y_min + y_max) // 2\n",
        "            x_min = max(0, x_center - side_length // 2)\n",
        "            x_max = x_min + side_length\n",
        "            y_min = max(0, y_center - side_length // 2)\n",
        "            y_max = y_min + side_length\n",
        "\n",
        "            if x_max > w:\n",
        "                x_max = w\n",
        "                x_min = w - side_length\n",
        "            if y_max > h:\n",
        "                y_max = h\n",
        "                y_min = h - side_length\n",
        "\n",
        "            cropped_image = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "            # Convert the cropped image to grayscale and process it\n",
        "            # final_processed_image = get_grayscale(cropped_image)\n",
        "            # cropped_image = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "            # # Do contrasted hand\n",
        "            # contrast_enhanced = get_grayscale(cropped_image)\n",
        "\n",
        "            cropped_image = cv2.resize(cropped_image, (256, 256))\n",
        "\n",
        "\n",
        "            mask = np.zeros(cropped_image.shape[:2], dtype=np.uint8)\n",
        "            mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "            mp_drawing.draw_landmarks(\n",
        "                mask_bgr, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
        "                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=1, circle_radius=2),\n",
        "                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=4)\n",
        "            )\n",
        "            landmarks = [lm for lm in hand_landmarks.landmark]\n",
        "            # adjusted_landmarks = [(int((lm.x - x_min/w) * side_length), int((lm.y - y_min/h) * side_length)) for lm in landmarks]\n",
        "            # adjusted_landmarks = [(int(lm.x * 256), int(lm.y * 256)) for lm in landmarks]\n",
        "            adjusted_landmarks = [(int((lm.x * w - x_min) / (x_max - x_min) * 256),\n",
        "                                   int((lm.y * h - y_min) / (y_max - y_min) * 256))\n",
        "                                  for lm in hand_landmarks.landmark]\n",
        "\n",
        "            # adjusted_landmarks = [(int(lm.x * 256), int(lm.y * 256)) for lm in landmarks]\n",
        "            palm = [adjusted_landmarks[i] for i in [0, 2, 5, 9, 13, 17]]\n",
        "            palm_indices = [0, 2, 5, 9, 13, 17] # This depends on the landmarks of the hand model\n",
        "            palm_points = np.array([adjusted_landmarks[i] for i in palm_indices], dtype=np.int32)\n",
        "            cv2.fillPoly(mask_bgr, [palm_points], (255, 255, 255))\n",
        "\n",
        "            mask = cv2.cvtColor(mask_bgr, cv2.COLOR_BGR2GRAY)\n",
        "            kernel = np.ones((15, 15), np.uint8)\n",
        "            mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "            hand_image = np.zeros(cropped_image.shape[:2], dtype=np.uint8)\n",
        "            hand_image[mask > 0] = 255\n",
        "            final_img = cv2.resize(hand_image, (128, 128))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            plt.figure(figsize=(3, 3))\n",
        "            plt.imshow(final_img, cmap='gray')  # Ensure it is displayed as grayscale\n",
        "            plt.title(f\"Processed Image\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "\n",
        "            return [final_img, None]\n",
        "        else:\n",
        "            return [None, None]"
      ],
      "metadata": {
        "id": "Ju-YabcCHamb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}