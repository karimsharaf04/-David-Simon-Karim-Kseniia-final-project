{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G91XOYrFnsP",
        "outputId": "228741a1-cb19-4af4-9e2e-92fe31a6eada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.3 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdvjwTZ4FgDO"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U08I340jFveS",
        "outputId": "56a0a8e2-f372-4064-b8f8-f2dd7236a4ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGtGWRoWFleJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the process_image function as provided before\n",
        "\n",
        "def get_grayscale(image):\n",
        "    # Convert image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Gaussian Blur\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (9, 9), 0)\n",
        "    # Enhance contrast\n",
        "    contrast_enhanced = cv2.equalizeHist(blurred_image)\n",
        "\n",
        "    # Resize image to maintain 1:1 aspect ratio and make it 128x128\n",
        "    target_size = 128\n",
        "    height, width = contrast_enhanced.shape\n",
        "    scale = target_size / max(height, width)\n",
        "    resized_image = cv2.resize(contrast_enhanced, (int(width * scale), int(height * scale)), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Centering the image in a 128x128 frame\n",
        "    delta_w = target_size - resized_image.shape[1]\n",
        "    delta_h = target_size - resized_image.shape[0]\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    # Add border to make the image exactly 128x128\n",
        "    final_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "    # Display the final processed image\n",
        "    # plt.figure(figsize=(3, 3))\n",
        "    # plt.imshow(final_image, cmap='gray')\n",
        "    # plt.title(\"Processed Image\")\n",
        "    # plt.axis('off')\n",
        "    # plt.show()\n",
        "\n",
        "    return final_image\n",
        "\n",
        "def process_image(image):\n",
        "    mp_hands = mp.solutions.hands\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
        "        results = hands.process(image)\n",
        "        if results.multi_hand_landmarks:\n",
        "            hand_landmarks = results.multi_hand_landmarks[0]\n",
        "            h, w, _ = image.shape\n",
        "\n",
        "            # Create a mask for drawing landmarks\n",
        "            mask = np.zeros((h, w), dtype=np.uint8)\n",
        "            mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            # Draw landmarks and connections using MediaPipe drawing utils\n",
        "            mp_drawing.draw_landmarks(\n",
        "                mask_bgr, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
        "                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=4, circle_radius=2),\n",
        "                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=22)\n",
        "            )\n",
        "\n",
        "            mask = cv2.cvtColor(mask_bgr, cv2.COLOR_BGR2GRAY)\n",
        "            kernel = np.ones((15, 15), np.uint8)\n",
        "\n",
        "\n",
        "            # Determine palm points for fillPoly\n",
        "            palm_indices = [0, 2, 5, 9, 13, 17]  # Indices for wrist and bases of each finger\n",
        "            palm_points = np.array([[\n",
        "                int(hand_landmarks.landmark[idx].x * w),\n",
        "                int(hand_landmarks.landmark[idx].y * h)\n",
        "            ] for idx in palm_indices], dtype=np.int32)\n",
        "\n",
        "            # Fill the palm area on the mask\n",
        "            cv2.fillPoly(mask, [palm_points], (255, 255, 255))\n",
        "            mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "            # Find contours to determine the bounding box of the hand\n",
        "            contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            if contours:\n",
        "                cnt = max(contours, key=cv2.contourArea)  # find the largest contour\n",
        "                x, y, w, h = cv2.boundingRect(cnt)\n",
        "\n",
        "                # Crop and resize the mask\n",
        "                cropped_mask = mask[y:y+h, x:x+w]\n",
        "                final_img = cv2.resize(cropped_mask, (128, 128))\n",
        "\n",
        "                plt.figure(figsize=(3, 3))\n",
        "                plt.imshow(final_img, cmap='gray')\n",
        "                plt.title(\"Processed Image\")\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "\n",
        "                return [final_img, None]\n",
        "        else:\n",
        "            return [None, None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EL-J70BWFm5T",
        "outputId": "14c62033-76ea-4572-e10e-a81b6e55b1f3"
      },
      "outputs": [],
      "source": [
        "# full_dir_path = os.path.join(base_dir, dir_name)\n",
        "training_path = '/content/drive/MyDrive/training_vids'\n",
        "output_path = '/content/drive/MyDrive/training_v2'\n",
        "# Create directories if they do not exist\n",
        "if not os.path.exists('frame_hands_v2'):\n",
        "    os.makedirs('frame_hands_v2')\n",
        "if not os.path.exists('bw_plain_hands_v3'):\n",
        "    os.makedirs('bw_plain_hands_v3')\n",
        "\n",
        "# Load the video\n",
        "videos = [\"closed_left\", \"closed_right\", \"open_left\", \"open_right\"]\n",
        "for vid in videos:\n",
        "  file_name = f'{training_path}/{vid}.mp4'\n",
        "  cap = cv2.VideoCapture(file_name)\n",
        "  frame_number = 0\n",
        "\n",
        "  while cap.isOpened():\n",
        "      print(\"Frame number:\", frame_number)\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "          break\n",
        "\n",
        "      # Process the image\n",
        "      processed_image, bw_image = process_image(frame)\n",
        "      source_video = file_name.split(\"/\")[-1][:-4]\n",
        "      if processed_image is not None:\n",
        "          cv2.imwrite(f'{output_path}/frame_hands_v2/frame_{source_video}_{frame_number}.png', processed_image)\n",
        "          # cv2.imwrite(f'{output_path}/bw_plain_hands_v3/frame_{source_video}_{frame_number}.png', bw_image)\n",
        "          print(f'SAVED: {output_path}/frame_hands_v2/frame_{source_video}_{frame_number}.png')\n",
        "          # print(f'SAVED: {output_path}/bw_plain_hands_v3/frame_{source_video}_{frame_number}.png')\n",
        "\n",
        "      frame_number += 1\n",
        "\n",
        "cap.release()\n",
        "print(\"Processing complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju-YabcCHamb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the process_image function as provided before\n",
        "\n",
        "def get_grayscale(image):\n",
        "    # Convert image to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Gaussian Blur\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (9, 9), 0)\n",
        "    # Enhance contrast\n",
        "    contrast_enhanced = cv2.equalizeHist(blurred_image)\n",
        "\n",
        "    # Resize image to maintain 1:1 aspect ratio and make it 128x128\n",
        "    target_size = 128\n",
        "    height, width = contrast_enhanced.shape\n",
        "    scale = target_size / max(height, width)\n",
        "    resized_image = cv2.resize(contrast_enhanced, (int(width * scale), int(height * scale)), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Centering the image in a 128x128 frame\n",
        "    delta_w = target_size - resized_image.shape[1]\n",
        "    delta_h = target_size - resized_image.shape[0]\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    # Add border to make the image exactly 128x128\n",
        "    final_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "    # Display the final processed image\n",
        "    # plt.figure(figsize=(3, 3))\n",
        "    # plt.imshow(final_image, cmap='gray')\n",
        "    # plt.title(\"Processed Image\")\n",
        "    # plt.axis('off')\n",
        "    # plt.show()\n",
        "\n",
        "    return final_image\n",
        "\n",
        "def process_image(image):\n",
        "    mp_hands = mp.solutions.hands\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
        "        results = hands.process(image)\n",
        "        if results.multi_hand_landmarks:\n",
        "\n",
        "\n",
        "            hand_landmarks = results.multi_hand_landmarks[0]\n",
        "            h, w, _ = image.shape\n",
        "            x_min, x_max = int(min(lm.x for lm in hand_landmarks.landmark) * w), int(max(lm.x for lm in hand_landmarks.landmark) * w)\n",
        "            y_min, y_max = int(min(lm.y for lm in hand_landmarks.landmark) * h), int(max(lm.y for lm in hand_landmarks.landmark) * h)\n",
        "\n",
        "\n",
        "\n",
        "#----------------\n",
        "           # Adjust to keep the aspect ratio 1:1 and include padding\n",
        "            box_width = x_max - x_min\n",
        "            box_height = y_max - y_min\n",
        "            side_length = max(box_width, box_height)\n",
        "            padding = int(side_length * 0.05)\n",
        "            side_length += 2 * padding\n",
        "\n",
        "            # Center the square around the hand, adjust if it goes out of bounds\n",
        "            x_center = (x_min + x_max) // 2\n",
        "            y_center = (y_min + y_max) // 2\n",
        "            x_min = max(0, x_center - side_length // 2)\n",
        "            x_max = x_min + side_length\n",
        "            y_min = max(0, y_center - side_length // 2)\n",
        "            y_max = y_min + side_length\n",
        "\n",
        "            if x_max > w:\n",
        "                x_max = w\n",
        "                x_min = w - side_length\n",
        "            if y_max > h:\n",
        "                y_max = h\n",
        "                y_min = h - side_length\n",
        "\n",
        "            cropped_image = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "            # Convert the cropped image to grayscale and process it\n",
        "            # final_processed_image = get_grayscale(cropped_image)\n",
        "            # cropped_image = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "            # # Do contrasted hand\n",
        "            # contrast_enhanced = get_grayscale(cropped_image)\n",
        "\n",
        "            cropped_image = cv2.resize(cropped_image, (256, 256))\n",
        "\n",
        "\n",
        "            mask = np.zeros(cropped_image.shape[:2], dtype=np.uint8)\n",
        "            mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "            mp_drawing.draw_landmarks(\n",
        "                mask_bgr, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
        "                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=1, circle_radius=2),\n",
        "                mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=4)\n",
        "            )\n",
        "            landmarks = [lm for lm in hand_landmarks.landmark]\n",
        "            # adjusted_landmarks = [(int((lm.x - x_min/w) * side_length), int((lm.y - y_min/h) * side_length)) for lm in landmarks]\n",
        "            # adjusted_landmarks = [(int(lm.x * 256), int(lm.y * 256)) for lm in landmarks]\n",
        "            adjusted_landmarks = [(int((lm.x * w - x_min) / (x_max - x_min) * 256),\n",
        "                                   int((lm.y * h - y_min) / (y_max - y_min) * 256))\n",
        "                                  for lm in hand_landmarks.landmark]\n",
        "\n",
        "            # adjusted_landmarks = [(int(lm.x * 256), int(lm.y * 256)) for lm in landmarks]\n",
        "            palm = [adjusted_landmarks[i] for i in [0, 2, 5, 9, 13, 17]]\n",
        "            palm_indices = [0, 2, 5, 9, 13, 17] # This depends on the landmarks of the hand model\n",
        "            palm_points = np.array([adjusted_landmarks[i] for i in palm_indices], dtype=np.int32)\n",
        "            cv2.fillPoly(mask_bgr, [palm_points], (255, 255, 255))\n",
        "\n",
        "            mask = cv2.cvtColor(mask_bgr, cv2.COLOR_BGR2GRAY)\n",
        "            kernel = np.ones((15, 15), np.uint8)\n",
        "            mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "            hand_image = np.zeros(cropped_image.shape[:2], dtype=np.uint8)\n",
        "            hand_image[mask > 0] = 255\n",
        "            final_img = cv2.resize(hand_image, (128, 128))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            plt.figure(figsize=(3, 3))\n",
        "            plt.imshow(final_img, cmap='gray')  # Ensure it is displayed as grayscale\n",
        "            plt.title(f\"Processed Image\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "\n",
        "            return [final_img, None]\n",
        "        else:\n",
        "            return [None, None]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
